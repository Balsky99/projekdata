{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Library\n\n#Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n#Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Statistics\nfrom scipy.stats import kurtosis\nfrom scipy.stats import skew,iqr\nfrom scipy import stats\n\n#Modelling\nfrom sklearn.metrics import roc_auc_score\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTEENN,SMOTETomek,SMOTEENN\nfrom sklearn.model_selection import StratifiedKFold, learning_curve\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import linear_model\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n#File Management System\nimport os\n\n#Surpress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/sanbercode-data-science/Pendapatan.csv')\ntest = pd.read_csv('/kaggle/input/sanbercode-data-science/Pendapatan_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order=test['id']\noo = train['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nval = train['Gaji'].value_counts()\nlabel = ['<=5jt', '>5jt']\n\nplt.pie(val, labels = label, startangle = 90, autopct = '%.1f%%')\nplt.title('Pie Chart of Survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Status Perkawinan'].value_counts().div(len(train['Status Perkawinan']))*100)\n\n#Full Stacked Barplot cross selling berdasarkan gender\n\ncs_em = pd.crosstab(train['Status Perkawinan'], train['Gaji'])\ncs_em = cs_em.div(cs_em.sum())\nax = cs_em.T.plot(kind='bar', stacked = False, rot = 1, figsize = (6,6),\n                 title = 'Gaji across Status Perkawinan')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Pekerjaan'].value_counts().div(len(train['Pekerjaan']))*100)\n\n#Full Stacked Barplot cross selling berdasarkan gender\n\ncs_em = pd.crosstab(train['Pekerjaan'], train['Gaji'])\ncs_em = cs_em.div(cs_em.sum())\nax = cs_em.T.plot(kind='bar', stacked = False, rot = 1, figsize = (12,8),\n                 title = 'Gaji across Pekerjaaan')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Pendidikan'].value_counts().div(len(train['Pendidikan']))*100)\n\n#Full Stacked Barplot cross selling berdasarkan gender\n\ncs_em = pd.crosstab(train['Pendidikan'], train['Gaji'])\ncs_em = cs_em.div(cs_em.sum())\nax = cs_em.T.plot(kind='bar', stacked = False, rot = 1, figsize = (12,8),\n                 title = 'Gaji across Pendidikan')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Kelas Pekerja'].value_counts().div(len(train['Kelas Pekerja']))*100)\n\n#Full Stacked Barplot cross selling berdasarkan gender\n\ncs_em = pd.crosstab(train['Kelas Pekerja'], train['Gaji'])\ncs_em = cs_em.div(cs_em.sum())\nax = cs_em.T.plot(kind='bar', stacked = False, rot = 1, figsize = (12,8),\n                 title = 'Gaji across Kelas')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Jenis Kelamin'].value_counts().div(len(train['Jenis Kelamin']))*100)\n\n#Full Stacked Barplot cross selling berdasarkan gender\n\ncs_em = pd.crosstab(train['Jenis Kelamin'], train['Gaji'])\ncs_em = cs_em.div(cs_em.sum())\nax = cs_em.T.plot(kind='bar', stacked = False, rot = 1, figsize = (12,8),\n                 title = 'Gaji across Jenis Kelamin')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sn\nplt.figure(figsize = (8,6))\n\nsn.kdeplot(train.loc[train['Gaji'] == 0, 'Umur'], label = 'Gaji <= 5jt')\nsn.kdeplot(train.loc[train['Gaji'] == 1, 'Umur'], label = 'Gaji > 5jt')\n\nplt.xlabel('Umur')\nplt.ylabel('density')\nplt.title('Distribution of Umur')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\n\nsn.kdeplot(train.loc[train['Gaji'] == 0, 'Jam per Minggu'], label = 'Gaji <= 5jt')\nsn.kdeplot(train.loc[train['Gaji'] == 1, 'Jam per Minggu'], label = 'Gaji > 5jt')\n\nplt.xlabel('Jam')\nplt.ylabel('density')\nplt.title('Distribution of Jam')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PREPOSESSING DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train['Gaji']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg, pos = np.bincount(train['Gaji'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batas=train['Gaji'].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace unknon value with nan\ntrain.replace({'?':np.nan}, inplace=True)\ntest.replace({'?':np.nan}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['id','Gaji'], axis = 1)\ntest = test.drop(['id'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.concat([train,test]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.groupby(['Pendidikan'])['Jmlh Tahun Pendidikan'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['Pendidikan'] = features['Pendidikan'].replace(['SD','1st-4th'],'Putus Sekolah')\nfeatures['Pendidikan'] = features['Pendidikan'].replace(['10th','11th','12th'], 'SMP')\nfeatures['Pendidikan'] = features['Pendidikan'].replace(['5th-6th','7th-8th','9th'], 'SD')\nfeatures['Pendidikan'] = features['Pendidikan'].replace('Pendidikan Tinggi', 'D1')\nfeatures['Pendidikan'] = features['Pendidikan'].replace('D4', 'D2')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['Status Perkawinan'] = features['Status Perkawinan'].replace(['Berpisah','Menikah LDR'],'LDR')\nfeatures['Status Perkawinan'] = features['Status Perkawinan'].replace(['Cerai','Janda'], 'Bercerai')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['Kelas Pekerja'] = features['Kelas Pekerja'].replace(['Pemerintah Lokal','Pemerintah Negara','Pemerintah Provinsi'],'Pemerintahan')\nfeatures['Kelas Pekerja'] = features['Kelas Pekerja'].replace(['Tanpa di Bayar','Tidak Pernah Bekerja'], 'Tidak Bekerja')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding = features.groupby('Status Perkawinan').size()\nencoding = encoding/len(features)\nfeatures['freq_Status_Perkawinan']=features['Status Perkawinan'].map(encoding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding = features.groupby('Jenis Kelamin').size()\nencoding = encoding/len(features)\nfeatures['freq_Jenis_Kelamin']=features['Jenis Kelamin'].map(encoding)\n\nencoding = features.groupby('Pendidikan').size()\nencoding = encoding/len(features)\nfeatures['freq_Pendidikan']=features['Pendidikan'].map(encoding)\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fancyimpute import KNN\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.impute import KNNImputer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ENCODE TIPE KATEGORIK"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = OrdinalEncoder()\nimputer = KNN()\ncols = ['Kelas Pekerja','Pendidikan','Status Perkawinan','Pekerjaan','Jenis Kelamin']\n\ndef encode(data):\n    nonulls=np.array(data.dropna())\n    impute_reshape = nonulls.reshape(-1,1)\n    impute_ordinal = encoder.fit_transform(impute_reshape)\n    data.loc[data.notnull()]=np.squeeze(impute_ordinal)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for columns in cols:\n    encode(features[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['Pekerjaan'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features['Kelas Pekerja'] = features['Kelas Pekerja'].fillna(features['Kelas Pekerja'].mode()[0])\nfeatures['Pekerjaan'] = features['Pekerjaan'].fillna(features['Pekerjaan'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import seaborn as sns\n#cancel_corr = features.corr()['Gaji']\n#cancel_corr.abs().sort_values(ascending= False)[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding = features.groupby('Kelas Pekerja').size()\nencoding = encoding/len(features)\nfeatures['Freq_Kelas_Pekerja']=features['Kelas Pekerja'].map(encoding)\n\nencoding = features.groupby('Pekerjaan').size()\nencoding = encoding/len(features)\nfeatures['Freq_Pekerjaan']=features['Pekerjaan'].map(encoding)\nfeatures","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Menambahkan kolom baru"},{"metadata":{"trusted":true},"cell_type":"code","source":"features['Net_Kapital'] = features['Keuntungan Kapital']-features['Kerugian Capital']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.get_dummies(features, columns =['Jenis Kelamin','Status Perkawinan','Kelas Pekerja','Pekerjaan'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.var()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n#features = scaler.fit_transform(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(df):\n    result = df.copy()\n    for feature_name in df.columns:\n        max_value = df[feature_name].max()\n        min_value = df[feature_name].min()\n        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n    return result\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = normalize(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BUILT MODEL (MODELLING)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = features.iloc[:len(y),:]\nX_sub = features.iloc[len(y):,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df = X.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, learning_curve\nskf = StratifiedKFold(n_splits= 10, random_state = 7)\nskf.get_n_splits(X, y)\nfor train_index, test_index in skf.split(X,y):\n    print (\"Train:\", train_index, 'Validation:', test_index)\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)\nX_test = np.array(X_test)\ny_train= np.array(y_train)\ny_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport os\nimport tempfile\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DEFINE AND TRAIN  MODEL USING KERAS"},{"metadata":{"trusted":true},"cell_type":"code","source":"METRICS = [\n      keras.metrics.AUC(name='auc'),\n]\n\n\ndef make_model(metrics = METRICS, output_bias=None):\n    if output_bias is not None:\n        output_bias = tf.keras.initializers.Constant(output_bias)\n    model = keras.Sequential([\n      keras.layers.Dense(\n          38, activation='relu',\n          input_shape=(38,)),\n      keras.layers.Dropout(0.5),keras.layers.Dense(16, activation='relu'),\n        keras.layers.Dropout(0.5),\n      keras.layers.Dense(1, activation='sigmoid',\n                         bias_initializer=output_bias),\n  ])\n\n    model.compile(\n      optimizer=keras.optimizers.Adam(lr=1e-3),\n      loss=keras.losses.BinaryCrossentropy(),\n      metrics=metrics)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 100\nBATCH_SIZE = 2048\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_auc', \n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True)\n\nmodel = make_model()\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(X_train[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"REDUCE BIAS IN MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=0)\nprint(\"Loss: {:0.4f}\".format(results[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_bias = np.log([pos/neg])\ninitial_bias","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = make_model(output_bias = initial_bias)\nmodel.predict(X_train[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=0)\nprint(\"Loss: {:0.4f}\".format(results[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\nmodel.save_weights(initial_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = make_model()\nmodel.load_weights(initial_weights)\nzero_bias_history = model.fit(\n    X_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=20,\n    validation_data=(X_test, y_test), \n    verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = make_model()\nmodel.load_weights(initial_weights)\ncareful_bias_history = model.fit(\n    X_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=20,\n    validation_data=(X_test, y_test), \n    verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = make_model()\nmodel.load_weights(initial_weights)\nbaseline_history = model.fit(\n    X_train,y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks = [early_stopping],\n    validation_data=(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_for_0 = (1 / neg)*(total)/2.0 \nweight_for_1 = (1 / pos)*(total)/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using weight class karena data bersifat imbalanced (pendapatan yang dibawah 5jt terlalu dominan dibanding >5jt)"},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_model = make_model()\nweighted_model.load_weights(initial_weights)\n\nweighted_history = weighted_model.fit(\n    X_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks = [early_stopping],\n    validation_data=(X_test, y_test),\n    # The class weights go here\n    class_weight=class_weight) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PREDICT DATA TEST PENDAPATAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sub= np.array(X_sub)\nX_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keket = weighted_model.predict(X_sub)\nyu = np.array(keket)\ndgg = pd.DataFrame(order)\ndgg['Gaji']= yu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\ndgg.to_csv('dgg.csv', index=False)\n\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe which was saved with .to_csv method\ncreate_download_link(filename='dgg.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}